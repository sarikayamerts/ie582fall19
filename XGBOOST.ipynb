{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from utils import ranked_probability_loss\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "def ranked_probability_loss_metric(obs, preds):\n",
    "  \"\"\"\n",
    "  >>> y_true = [1, 1]\n",
    "  >>> y_prob = [[0.5, 0.3, 0.2], [0.5, 0.2, 0.3]]\n",
    "  >>> ranked_probability_loss(y_true, y_prob) # array([0.145, 0.17 ])\n",
    "\n",
    "  >>> y_true = [1]\n",
    "  >>> y_prob = [[0.7, 0.3, 0]]\n",
    "  >>> ranked_probability_loss(y_true, y_prob) # array([0.045])\n",
    "  \"\"\"\n",
    "  result_mapping = {1: [1, 0, 0],\n",
    "                  0: [0, 1, 0],\n",
    "                  2: [0, 0, 1]}\n",
    "\n",
    "  obs = check_array(obs, ensure_2d=False)\n",
    "  preds = check_array(preds, ensure_2d=False)\n",
    "  obs = np.array([result_mapping[i] for i in obs])\n",
    "\n",
    "  cum_diff = np.cumsum(preds, axis=1) - np.cumsum(obs, axis=1)\n",
    "  result = np.sum(np.square(cum_diff), axis=1)/2\n",
    "  return np.round(result, 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "bets = pd.read_csv(\"data/bets.zip\")\n",
    "booking = pd.read_csv(\"data/booking.zip\")\n",
    "goals = pd.read_csv(\"data/goals.zip\")\n",
    "matches = pd.read_csv(\"data/matches.zip\")\n",
    "stats = pd.read_csv(\"data/stats.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting epoch column to datetime\n",
    "matches['timestamp'] = matches['epoch'].apply(lambda x: dt.datetime.fromtimestamp(x))\n",
    "bets['timestamp'] = bets['odd_epoch'].apply(lambda x: dt.datetime.fromtimestamp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_converter(timestamp):\n",
    "  \"\"\"\n",
    "  year is 2019 for dates between 2019-07 and 2020-06, \n",
    "  22nd week just random splitter, \n",
    "  there might be better representation\n",
    "  \n",
    "  is_national is True for Friday, Saturday, Sunday, Monday \n",
    "  False otherwise\n",
    "  \"\"\"\n",
    "  # year = (timestamp - dt.timedelta(1)).dt.strftime('%Y')\n",
    "  year, week, day = (timestamp - dt.timedelta(1)).isocalendar()\n",
    "  year = year - 1 if week < 22 else year\n",
    "  is_national = day >= 4\n",
    "  return [year, week, is_national]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[['year','week', 'is_national']] = pd.DataFrame(matches.timestamp.apply(week_converter).values.tolist(), \n",
    "                                                       index=matches.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-12-05'\n",
    "end_date = '2020-01-01'\n",
    "league_id = 148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 690\n",
      "12 690\n",
      "12 690\n",
      "12 690\n"
     ]
    }
   ],
   "source": [
    "matches = matches[matches[\"league_id\"] == 148]\n",
    "test_matches = matches[matches['timestamp'] > start_date]\n",
    "matches = matches[matches['timestamp'] < start_date]\n",
    "print(len(test_matches), len(matches))\n",
    "\n",
    "if end_date:\n",
    "  test_matches = test_matches[test_matches['timestamp'] < end_date]\n",
    "  print(len(test_matches), len(matches))\n",
    "    \n",
    "if league_id:\n",
    "  test_matches = test_matches[test_matches['league_id'] == league_id]\n",
    "  print(len(test_matches), len(matches))\n",
    "    \n",
    "matches = matches.dropna(subset=['match_status', 'match_hometeam_score', 'match_awayteam_score'])\n",
    "print(len(test_matches), len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting bets to odd1 oddx odd2 only\n",
    "# odd values should be more than \n",
    "bets = bets[bets['value'] > 1]\n",
    "bets = bets[bets['variable'].isin(['odd_1', 'odd_x', 'odd_2'])]\n",
    "\n",
    "bets = bets.pivot_table(index=['match_id', 'odd_bookmakers', 'timestamp'],\n",
    "                        columns='variable',\n",
    "                        values='value').reset_index()\n",
    "\n",
    "# pivoting bets data to see the changes with time easily and \n",
    "# see the odds in a single row for each match - bookmaker - timestamp\n",
    "\n",
    "bets = bets[['match_id', 'odd_bookmakers', 'odd_1', 'odd_x', 'odd_2', 'timestamp']].dropna()\n",
    "\n",
    "# Since bets are changing by time, I will use final odds announced by bookmakers\n",
    "# by assuming they are correcting their odds somehow\n",
    "\n",
    "final_bets = bets.groupby(['match_id', 'odd_bookmakers'], as_index=False).last()\n",
    "first_bets = bets.groupby(['match_id', 'odd_bookmakers'], as_index=False).first()\n",
    "\n",
    "final_bets[\"BetType\"] = \"Final\"\n",
    "first_bets[\"BetType\"] = \"First\"\n",
    "\n",
    "final_bets = pd.concat([first_bets, final_bets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating implied naive probabilities and creating new prob_odd_1(x,2) columns\n",
    "for cols in ['odd_1', 'odd_x', 'odd_2']:\n",
    "  final_bets['prob_'+cols] = 1 / final_bets[cols]\n",
    "\n",
    "# Summing all naive probabilities for each bookmaker & match (this will give us 1 + margin of bookmaker)\n",
    "final_bets['total'] = final_bets['prob_odd_1'] + final_bets['prob_odd_x'] + final_bets['prob_odd_2']\n",
    "\n",
    "# normalizin odd by removing margin share from each of them\n",
    "for cols in ['odd_1', 'odd_x', 'odd_2']:\n",
    "  final_bets['norm_prob_'+cols] = final_bets['prob_'+cols] / final_bets['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a result column 1, 0 or 2 for home win, draw, away win accordingly\n",
    "\n",
    "matches['result'] = np.where(matches.match_hometeam_score > matches.match_awayteam_score, \n",
    "                             1, 0)\n",
    "# if away > home, then returns 2. otherwise returns the previous result value \n",
    "# (which is 1 if home > away and 0 otherwise)\n",
    "\n",
    "matches['result'] = np.where(matches.match_hometeam_score < matches.match_awayteam_score, \n",
    "                             2, matches.result)\n",
    "\n",
    "# joining result info into the final bets table\n",
    "\n",
    "final_bets = final_bets.merge(matches[['match_id', 'result', 'year', 'week', 'is_national']], \n",
    "                              on='match_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bets['rps'] = ranked_probability_loss(final_bets['result'], \n",
    "                                            final_bets[['norm_prob_odd_1', 'norm_prob_odd_x', 'norm_prob_odd_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker_list = final_bets.groupby(['odd_bookmakers']).agg({'result': 'count'})\n",
    "bookmaker_list = bookmaker_list[bookmaker_list[\"result\"] > 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'odd_bookmakers', 'odd_1', 'odd_x', 'odd_2', 'timestamp',\n",
       "       'BetType', 'prob_odd_1', 'prob_odd_x', 'prob_odd_2', 'total',\n",
       "       'norm_prob_odd_1', 'norm_prob_odd_x', 'norm_prob_odd_2', 'result',\n",
       "       'year', 'week', 'is_national'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bets_input = final_bets[[\"match_id\", \"timestamp\", \"norm_prob_odd_1\", \"norm_prob_odd_x\", \"norm_prob_odd_2\", \"BetType\", \"odd_bookmakers\", \"result\"]]\n",
    "\n",
    "final_bets_input = final_bets_input.pivot_table(index=[\"result\", \"match_id\", 'timestamp'],\n",
    "                             columns= [\"odd_bookmakers\", \"BetType\"],\n",
    "                             values=['norm_prob_odd_1', 'norm_prob_odd_x', 'norm_prob_odd_2']).reset_index()\n",
    "\n",
    "final_bets_input.columns = final_bets_input.columns.map('{0[1]}_{0[0]}_{0[2]}'.format)\n",
    "\n",
    "final_bets_input.rename(columns={'_timestamp_':'timestamp',\n",
    "                          '_match_id_':'match_id',\n",
    "                                \"_result_\":\"result\"}, \n",
    "                 inplace=True)\n",
    "\n",
    "final_bets_input[\"Year\"] = final_bets_input[\"timestamp\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bets_input = final_bets_input.fillna(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bets_input = final_bets_input.drop(\"timestamp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logistic_model = LogisticRegression(multi_class='multinomial', solver='newton-cg', max_iter=1000)\n",
    "\n",
    "ranked_probability_loss_metric(final_bets_input[\"result\"], ridge_model.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:   11.8s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=8, random_state=7, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     needs_proba=True, nt...\n",
       "             param_grid={'colsample_bytree': [0.7], 'learning_rate': [0.01],\n",
       "                         'max_depth': [2], 'min_child_weight': [11],\n",
       "                         'n_estimators': [100], 'nthread': [4],\n",
       "                         'objective': ['multi:softprob'], 'seed': [1337],\n",
       "                         'silent': [1], 'subsample': [0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(ranked_probability_loss_metric, greater_is_better=False, needs_proba=True),\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(needs_proba=True)\n",
    "kfold = StratifiedKFold(n_splits=8, shuffle=True, random_state=7)\n",
    "\n",
    "label_encoded_y = LabelEncoder().fit_transform(final_bets_input[\"result\"])\n",
    "X = final_bets_input.drop('result', axis=1)\n",
    "\n",
    "scorer = make_scorer(ranked_probability_loss_metric, greater_is_better=False, needs_proba=True)\n",
    "\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softprob'],\n",
    "              'learning_rate': [0.01, 0.05], #so called `eta` value\n",
    "              'max_depth': [2, 4],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.6, 0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 250], #number of trees, change it to 1000 for better results\n",
    "              'seed': [1337]}\n",
    "\n",
    "clf = GridSearchCV(model, parameters, n_jobs=-1, \n",
    "                   cv=kfold, \n",
    "                   scoring= scorer,\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(X, label_encoded_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24995947194719476"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X)\n",
    "ranked_probability_loss_metric(final_bets_input[\"result\"], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.293065"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list = matches[(matches[\"league_id\"] == 148) & (matches[\"timestamp\"] > '2019-11-20')]\n",
    "match_list = match_list[\"match_id\"].values.tolist()\n",
    "\n",
    "test = final_bets_input[final_bets_input[\"match_id\"].isin(match_list)]\n",
    "y_pred = clf.predict_proba(test.drop('result', axis=1))\n",
    "\n",
    "ranked_probability_loss_metric(test['result'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erdem.banak\\AppData\\Local\\Continuum\\anaconda3\\envs\\erdem\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RidgeClassifier' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-1b8a53ee29ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_bets_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal_bets_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"match_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mranked_probability_loss_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RidgeClassifier' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "#y_pred, test[\"result\"]\n",
    "\n",
    "test = final_bets_input[final_bets_input[\"match_id\"].isin(match_list)]\n",
    "y_pred = ridge_model.predict_proba(test.drop('result', axis=1))\n",
    "\n",
    "ranked_probability_loss_metric(test['result'], y_pred)\n",
    "\n",
    "ridge_params = {'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\n",
    "\n",
    "models2 = GridSearchCV(RidgeClassifier(), \n",
    "                               param_grid=ridge_params).fit(X, label_encoded_y).best_estimator_\n",
    "\n",
    "test = final_bets_input[final_bets_input[\"match_id\"].isin(match_list)]\n",
    "y_pred = models2.predict_proba(test.drop('result', axis=1))\n",
    "\n",
    "ranked_probability_loss_metric(test['result'], y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erdem.banak\\AppData\\Local\\Continuum\\anaconda3\\envs\\erdem\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RidgeClassifier' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-3569b2e3741a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_bets_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal_bets_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"match_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mranked_probability_loss_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RidgeClassifier' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "ridge_params = {'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\n",
    "\n",
    "models2 = GridSearchCV(RidgeClassifier(), \n",
    "                               param_grid=ridge_params).fit(X, label_encoded_y).best_estimator_\n",
    "\n",
    "test = final_bets_input[final_bets_input[\"match_id\"].isin(match_list)]\n",
    "y_pred = models2.predict_proba(test.drop('result', axis=1))\n",
    "\n",
    "ranked_probability_loss_metric(test['result'], y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bets_input[final_bets_input[\"match_id\"].isin(match_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
