{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.validation import check_array\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn import tree\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from itertools import chain\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import l1_min_c    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function cleans the bets data; returns a reliable bettor list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bookies_to_keep(start_date, end_date, ratio):\n",
    "    bets = pd.read_csv(\"data/bets.zip\")\n",
    "    matches = pd.read_csv(\"data/matches.zip\")\n",
    "\n",
    "    # Converting epoch column to datetime\n",
    "    matches['timestamp'] = matches['epoch'].apply(\n",
    "        lambda x: dt.datetime.fromtimestamp(x))\n",
    "    bets['timestamp'] = bets['odd_epoch'].apply(\n",
    "        lambda x: dt.datetime.fromtimestamp(x))\n",
    "\n",
    "    matches = matches[(matches['timestamp'] > start_date) &\n",
    "                      (matches['timestamp'] < end_date) &\n",
    "                      (matches['league_id'] == 148)]\n",
    "\n",
    "    matches = matches.dropna(\n",
    "        subset=['match_status', 'match_hometeam_score',\n",
    "                'match_awayteam_score'])\n",
    "\n",
    "    match_ids = list(matches.match_id)\n",
    "    bets = bets[bets['match_id'].isin(match_ids)]\n",
    "    bets = bets[bets['value'] > 1]\n",
    "    bets = bets[bets['variable'].isin(['odd_1', 'odd_x', 'odd_2'])]\n",
    "\n",
    "    bets = bets.pivot_table(index=['match_id', 'odd_bookmakers', 'timestamp'],\n",
    "                            columns='variable',\n",
    "                            values='value').reset_index()\n",
    "    bets = bets[['match_id', 'odd_bookmakers',\n",
    "                 'odd_1', 'odd_x', 'odd_2', 'timestamp']].dropna()\n",
    "\n",
    "    final_bets = bets.groupby(['match_id', 'odd_bookmakers'],\n",
    "                              as_index=False).last()\n",
    "\n",
    "    bookies = final_bets.groupby('odd_bookmakers').count()[['match_id']].reset_index()\n",
    "    bookies['total_matches'] = final_bets.match_id.nunique()\n",
    "    bookies['ratio'] = bookies['match_id'] / bookies['total_matches']\n",
    "    bookies.sort_values('ratio', ascending=False, inplace=True)\n",
    "    bookies.reset_index(drop=True, inplace=True)\n",
    "    bookies_to_keep = bookies[bookies['ratio'] > ratio]\n",
    "    return list(bookies_to_keep.odd_bookmakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_converter(timestamp):\n",
    "    \"\"\"\n",
    "    year is 2019 for dates between 2019-07 and 2020-06, \n",
    "    22nd week just random splitter, \n",
    "    there might be better representation\n",
    "    \n",
    "    is_national is True for Friday, Saturday, Sunday, Monday \n",
    "    False otherwise\n",
    "    \"\"\"\n",
    "    year, week, day = timestamp.isocalendar()\n",
    "    season = year - 1 if week < 27 else year\n",
    "    is_weekend = day >= 5 or day == 1  \n",
    "    return [timestamp, season, year, week, is_weekend]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the generation of bet related features, we first selected which bookmakers to use. We chose a starting point, and we looked for the overall odd availability levels for all bookmakers. If a bookmaker announced their odds at least %97.5 of the matches from the England Premiere league, we selected them. And after converting their bets to implied probabilities by normalizing them, we looked for the availability of odds within bookmakers. Most available bet types are 'odd_1', 'odd_x', 'odd_2', 'bts_yes', 'bts_no', 'o+1.5', 'u+1.5', 'o+2.5', 'u+2.5', 'o+3.5', 'u+3.5', 'o+4.5', 'u+4.5' and these are all related directly or indirectly with total goals scored. For all these categories we looked for their minimum, maximum, first, last and mean values (for each bookmakers), bigger implied probability (lower odds) represents higher expectation. So let's if first probability (and hence min probability) is low for a match, and then it increased (hence max and last values are high) this corresponds for something has changed in favor of that team, so might affect the total goals scored. This example is valid for all above bet types. If a match has very high mean probabilty of o+3.5, this might reveal the high probability of having more total scores than usual. And even selecting the most \"available\" bookmaker and their mostly announced bets, there might be some NA values, we replaced them with the mean values for that same type of bet from the remaining bookmakers. If all bookmakers skip that bet type for a match, we simply remove those matches from our history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bet_features(bookies_to_keep, na_ratio=0.15):\n",
    "    bets = pd.read_csv(\"data/bets.zip\")\n",
    "    bets = bets[bets[\"odd_bookmakers\"].isin(bookies_to_keep)]\n",
    "\n",
    "    bets['timestamp'] = bets['odd_epoch'].apply(\n",
    "        lambda x: dt.datetime.fromtimestamp(x))\n",
    "\n",
    "    bets = bets[bets['value'] > 1]\n",
    "    bet_groups = [['odd_1', 'odd_x', 'odd_2'],\n",
    "                    ['bts_yes', 'bts_no'],\n",
    "                    ['o+1.5', 'u+1.5'],\n",
    "                    ['o+2.5', 'u+2.5'],\n",
    "                    ['o+3.5', 'u+3.5'],\n",
    "                    ['o+4.5', 'u+4.5']]\n",
    "\n",
    "    bets = bets[bets['variable'].isin(list(chain.from_iterable(bet_groups)))]\n",
    "\n",
    "    bets = bets.pivot_table(index=['match_id', 'odd_bookmakers', 'timestamp'],\n",
    "                            columns='variable',\n",
    "                            values='value').reset_index()\n",
    "\n",
    "    for bet_type in bet_groups:\n",
    "        bets[bet_type] = bets[bet_type].rdiv(1)\n",
    "        bets[bet_type] = bets[bet_type].div(bets[bet_type].sum(axis=1),\n",
    "                                            axis=0)\n",
    "\n",
    "    bets = bets.sort_values(\n",
    "        ['timestamp', 'match_id', 'odd_bookmakers']).reset_index(drop=True)\n",
    "\n",
    "    standart_bets = bet_groups.pop(0)\n",
    "    new_bets = list(chain.from_iterable(bet_groups))\n",
    "    # the reason i did in this way, we may want to use different stats for\n",
    "    # odd1x2 types and over under types\n",
    "    bets_features = bets.groupby(['match_id', 'odd_bookmakers']).agg({\n",
    "        **{i: ['min', 'max', 'first', 'last', 'mean'] \n",
    "            for i in standart_bets},\n",
    "        **{i: ['min', 'max', 'first', 'last', 'mean'] \n",
    "            for i in new_bets}})\n",
    "\n",
    "    bets_features.columns = bets_features.columns.map('{0[0]}_{0[1]}'.format)\n",
    "    # bets_features.fillna(\n",
    "    #     value={i: 0 for i in bets_features.columns if i.endswith('var')},\n",
    "    #     inplace=True)    \n",
    "    mean_bets_features = bets_features.groupby('match_id').mean()\n",
    "\n",
    "    bets_features_pivoted = bets_features.pivot_table(\n",
    "        index=[\"match_id\"],\n",
    "        columns= [\"odd_bookmakers\"])\n",
    "\n",
    "    bets_features_pivoted.columns = bets_features_pivoted.columns.map('{0[1]}_{0[0]}'.format)\n",
    "\n",
    "    na_cols = bets_features_pivoted.isnull().sum()\n",
    "    keep = na_cols < (na_ratio * len(bets_features_pivoted))\n",
    "    cols_to_keep = keep[keep == True].index.values.tolist()\n",
    "    bets_features_pivoted = bets_features_pivoted[cols_to_keep]\n",
    "\n",
    "    for cols in bets_features_pivoted:\n",
    "        mean_col = '_'.join(cols.split('_')[1:])\n",
    "        bets_features_pivoted[cols] = bets_features_pivoted[cols].combine_first(\n",
    "            mean_bets_features[mean_col])\n",
    "\n",
    "    return bets_features_pivoted.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates features about matches. We are getting the historic and rolling (last 1/5 matches) performances (using mean) for the teams. How many goals on average the team concedes/scores is an important feature. We are also finding performance based on points and the performance difference between the teams.\n",
    "\n",
    "We are also checking on average how many matches of a team are under 2.5 in different dimensions. We also have features based on home/away. We are looking at the performance of home team when they are playing at home (the features ending with _pos).\n",
    "\n",
    "exp_goal5 and exp_goal1 might be used as naive predictors. First one looks at the expected goals in a match based on the last 5 match of the teams.\n",
    "\n",
    "point5diff gives us the performance difference between the teams based on last 5 matches.\n",
    "\n",
    "We also have clean sheet and scoring rates per team. It is clearly related to scoring. For the project we already worked on win - draw - lose ratios; so we put them on too. It is not directly related to scoring but they might end up being useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_match_features():\n",
    "    matches = pd.read_csv(\"data/matches.zip\")\n",
    "    matches['timestamp'] = matches['epoch'].apply(\n",
    "        lambda x: dt.datetime.fromtimestamp(x))\n",
    "    matches[['date', 'season', 'year', 'week', 'is_weekend']] = \\\n",
    "        pd.DataFrame(matches.timestamp.apply(week_converter).values.tolist(), \n",
    "                        index=matches.index)\n",
    "    matches = matches.sort_values(\"date\")\n",
    "\n",
    "    away_side = matches[[\"match_awayteam_id\", \"match_awayteam_name\", \n",
    "                            \"match_id\", \"season\", \"date\", \n",
    "                            \"match_awayteam_score\", \"match_hometeam_score\"]]\n",
    "    home_side = matches[[\"match_hometeam_id\", \"match_hometeam_name\", \n",
    "                            \"match_id\", \"season\", \"date\", \n",
    "                            \"match_hometeam_score\", \"match_awayteam_score\"]]\n",
    "    away_side[\"HomeAway\"] = \"Away\"\n",
    "    home_side[\"HomeAway\"] = \"Home\"\n",
    "    away_side.columns = ['team_id', 'team_name', \"match_id\", \n",
    "                            \"season\", \"date\", \"scored\", \"conceded\", \"home_away\"]\n",
    "    home_side.columns = ['team_id', 'team_name', \"match_id\", \n",
    "                            \"season\", \"date\", \"scored\", \"conceded\", \"home_away\"]\n",
    "    team_match = pd.concat([away_side, home_side])\n",
    "    team_match = team_match.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    team_match['point'] = np.nan\n",
    "    team_match.loc[team_match['scored'] > team_match['conceded'], 'point'] = 3\n",
    "    team_match.loc[team_match['scored'] == team_match['conceded'], 'point'] = 1\n",
    "    team_match.loc[team_match['scored'] < team_match['conceded'], 'point'] = 0\n",
    "\n",
    "    team_match['won'] = 0\n",
    "    team_match.loc[team_match['point'] == 3, 'won'] = 1\n",
    "    team_match['draw'] = 0\n",
    "    team_match.loc[team_match['point'] == 1, 'draw'] = 1\n",
    "    team_match['lost'] = 0\n",
    "    team_match.loc[team_match['point'] == 0, 'lost'] = 1\n",
    "    team_match['clean_sheet'] = 0\n",
    "    team_match.loc[team_match['conceded'] == 0, 'clean_sheet'] = 1\n",
    "    team_match['has_scored'] = 0\n",
    "    team_match.loc[team_match['scored'] > 0, 'has_scored'] = 0\n",
    "    team_match['over25'] = 0\n",
    "    team_match.loc[team_match['scored'] + team_match['conceded'] > 2, 'over25'] = 1\n",
    "    team_match['under25'] = 0\n",
    "    team_match.loc[team_match['scored'] + team_match['conceded'] < 3, 'under25'] = 1\n",
    "\n",
    "    roll1 = lambda x: x.rolling(1).mean().shift()\n",
    "    roll5 = lambda x: x.rolling(5, min_periods = 1).mean().shift()\n",
    "    historic = lambda x: x.expanding().mean().shift()\n",
    "\n",
    "    team_match[\"point1\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).point.apply(roll1).reset_index(0,drop=True)\n",
    "    team_match[\"goal_scored1\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).scored.apply(roll1).reset_index(0,drop=True)\n",
    "    team_match[\"goal_conceded1\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).conceded.apply(roll1).reset_index(0,drop=True)\n",
    "    team_match[\"total_goals1\"] = team_match[\"goal_conceded1\"] + team_match[\"goal_scored1\"]\n",
    "\n",
    "    team_match[\"point5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).point.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"goal_scored5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).scored.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"goal_conceded5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).conceded.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"clean_sheet5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).clean_sheet.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"over25_ratio5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).over25.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"under25_ratio5\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).under25.apply(roll5).reset_index(0,drop=True)\n",
    "    team_match[\"total_goals5\"] = team_match[\"goal_conceded5\"] + team_match[\"goal_scored5\"]\n",
    "\n",
    "    team_match[\"point1_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).point.apply(roll1).reset_index(0,drop=True)\n",
    "    team_match[\"goal_scored1_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).scored.apply(roll1).reset_index(0,drop=True)\n",
    "    team_match[\"goal_conceded1_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).conceded.apply(roll1).reset_index(0,drop=True)\n",
    "\n",
    "    team_match[\"performance_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).point.apply(historic).reset_index(0,drop=True)\n",
    "\n",
    "    team_match[\"draw_ratio\"] = team_match.groupby(\n",
    "        [\"team_id\"]).draw.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"win_ratio\"] = team_match.groupby(\n",
    "        [\"team_id\"]).won.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"lost_ratio\"] = team_match.groupby(\n",
    "        [\"team_id\"]).lost.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"over25_ratio\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).over25.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"under25_ratio\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).under25.apply(historic).reset_index(0,drop=True)\n",
    "\n",
    "    team_match[\"draw_ratio_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).draw.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"win_ratio_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).won.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"lost_ratio_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).lost.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"over25_ratio_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).over25.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"under25_ratio_season\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).under25.apply(historic).reset_index(0,drop=True)\n",
    "\n",
    "    team_match[\"draw_ratio_pos\"] = team_match.groupby(\n",
    "        [\"team_id\", \"home_away\"]).draw.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"win_ratio_pos\"] = team_match.groupby(\n",
    "        [\"team_id\", \"home_away\"]).won.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"lost_ratio_pos\"] = team_match.groupby(\n",
    "        [\"team_id\", \"home_away\"]).lost.apply(historic).reset_index(0,drop=True)\n",
    "\n",
    "    team_match[\"draw_ratio_season_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).draw.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"win_ratio_season_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).won.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"lost_ratio_season_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\", \"home_away\"]).lost.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"over25_ratio_season_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).over25.apply(historic).reset_index(0,drop=True)\n",
    "    team_match[\"under25_ratio_season_pos\"] = team_match.groupby(\n",
    "        [\"season\", \"team_id\"]).under25.apply(historic).reset_index(0,drop=True)\n",
    "\n",
    "    match_id_pos = team_match.columns.get_loc(\"match_id\")\n",
    "    point1_pos = team_match.columns.get_loc(\"point1\")\n",
    "    len_cols = len(team_match.columns)\n",
    "    \n",
    "    cols = list(range(match_id_pos,match_id_pos+1)) + list(range(point1_pos, len_cols))\n",
    "    home = team_match[team_match[\"home_away\"] == 'Home'].iloc[:, cols]\n",
    "    away = team_match[team_match[\"home_away\"] == 'Away'].iloc[:, cols]\n",
    "    team_stats = home.merge(away, on='match_id', how='inner', suffixes=('_home', '_away'))\n",
    "    \n",
    "    team_stats[\"point5_diff\"] = team_stats[\"point5_home\"] - team_stats[\"point5_away\"]\n",
    "    team_stats[\"point1_diff\"] = team_stats[\"point1_home\"] - team_stats[\"point1_away\"]\n",
    "\n",
    "    team_stats[\"performance_season_diff\"] = team_stats[\"performance_season_home\"] - team_stats[\"performance_season_away\"]\n",
    "    team_stats[\"exp_goal5\"] = (team_stats[\"total_goals5_home\"] + team_stats[\"total_goals5_away\"])/2\n",
    "    team_stats[\"exp_goal1\"] = (team_stats[\"total_goals1_home\"] + team_stats[\"total_goals1_away\"])/2\n",
    "    \n",
    "    team_stats = team_stats.dropna()\n",
    "\n",
    "    return team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(bets_df, matches_df):\n",
    "    final_df = bets_df.merge(matches_df, on='match_id').dropna()\n",
    "    matches = pd.read_csv(\"data/matches.zip\")\n",
    "    common_cols = [\"match_id\", \"match_hometeam_score\", \"match_awayteam_score\"]\n",
    "    matches = matches[common_cols]\n",
    "\n",
    "    matches[\"total_score\"] = matches[\"match_hometeam_score\"] + \\\n",
    "        matches[\"match_awayteam_score\"]\n",
    "    matches[\"over_under\"] = np.nan\n",
    "    matches.loc[matches.total_score >= 3, \"over_under\"] = \"over\"\n",
    "    matches.loc[matches.total_score < 3, \"over_under\"] = \"under\"\n",
    "\n",
    "    final_df = final_df.merge(matches, on=\"match_id\")\n",
    "    final_df = final_df.drop([\"match_hometeam_score\", \"match_awayteam_score\"], \n",
    "                             axis=1)\n",
    "    return final_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting train - test as 80/20. Since sequence might be important; we are using the last 20% of the data as the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookies_to_keep = find_bookies_to_keep('2018-01-01', '2019-12-01', 0.975)\n",
    "\n",
    "bets_df = generate_bet_features(bookies_to_keep)\n",
    "matches_df = generate_match_features()\n",
    "\n",
    "final_df = data_prepare(bets_df, matches_df)\n",
    "\n",
    "matches = pd.read_csv(\"data/matches.zip\")\n",
    "matches['timestamp'] = matches['epoch'].apply(\n",
    "    lambda x: dt.datetime.fromtimestamp(x))\n",
    "\n",
    "final_df = final_df.merge(matches[[\"match_id\", \"timestamp\"]], on = \"match_id\")\n",
    "\n",
    "final_df = final_df.sort_values(\"timestamp\")\n",
    "all_length = len(final_df)\n",
    "test_size = int(np.round(len(final_df)/5))\n",
    "\n",
    "final_df[\"test\"] = 0\n",
    "final_df.loc[final_df.tail(test_size).index, 'test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop([\"match_id\", \"over_under\", \"total_score\"], axis=1)\n",
    "y = final_df[[\"total_score\", \"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X[\"test\"] == 0].drop([\"test\", \"timestamp\"], axis = 1)\n",
    "X_test = X[X[\"test\"] == 1].drop([\"test\", \"timestamp\"], axis = 1)\n",
    "y_train_reg = y[y[\"test\"] == 0][\"total_score\"]\n",
    "y_test_reg = y[y[\"test\"] == 1][\"total_score\"]\n",
    "y_train_class = y_train_reg > 2.5\n",
    "y_test_class = y_test_reg > 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classification(X, y):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    rfc=RandomForestClassifier(random_state=42, oob_score = True)\n",
    "    param_grid = { \n",
    "        'bootstrap': [True],\n",
    "        'n_estimators': [500],\n",
    "        'max_features': ['sqrt', 'log2', 15, 25, 40],\n",
    "        'min_samples_leaf' : [5]\n",
    "    }\n",
    "    kfold = StratifiedKFold(n_splits=8, shuffle=True, random_state=7)\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, \n",
    "                        param_grid=param_grid, \n",
    "                        cv= kfold, \n",
    "                        verbose=True, n_jobs=-1, return_train_score=True)\n",
    "    CV_rfc.fit(X, y)\n",
    "    return CV_rfc\n",
    "\n",
    "def rf_regression(X, y):\n",
    "    rfc=RandomForestRegressor(random_state=42)\n",
    "    param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'n_estimators': [500],\n",
    "        'max_features': ['sqrt', 'log2', 15, 25, 40],\n",
    "        'min_samples_leaf' : [5],\n",
    "        'max_depth': [4, 10]\n",
    "    }\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, \n",
    "                        param_grid=param_grid, \n",
    "                        cv= 8, \n",
    "                        verbose=True, n_jobs=-1, scoring = \"neg_mean_squared_error\", return_train_score=True)\n",
    "    CV_rfc.fit(X, y)\n",
    "    return CV_rfc\n",
    "\n",
    "def xgb_classifier(X,y):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    xgb = XGBClassifier()\n",
    "    kfold = StratifiedKFold(n_splits=8, shuffle=True, random_state=7)\n",
    "\n",
    "    param_grid = {'objective':['binary:logistic'],\n",
    "                  'learning_rate': [0.05, 0.1, 0.2],\n",
    "                  'max_depth': [2, 4, 6],\n",
    "                  'min_child_weight': [11],\n",
    "                  'silent': [1],\n",
    "                  'subsample': [0.7],\n",
    "                  'colsample_bytree': [0.7],\n",
    "                  'n_estimators': [100, 250, 500],\n",
    "                  'seed': [1337]}\n",
    "    \n",
    "    CV_xgb = GridSearchCV(estimator=xgb, \n",
    "                        param_grid=param_grid, \n",
    "                        cv= kfold, \n",
    "                        verbose=True, n_jobs=-1, return_train_score=True)\n",
    "    CV_xgb.fit(X, y)\n",
    "    \n",
    "    return CV_xgb\n",
    "\n",
    "def xgb_regression(X,y):\n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    param_grid = {'objective':['reg:linear'],\n",
    "                  'learning_rate': [0.05, 0.1, 0.2],\n",
    "                  'max_depth': [2, 4, 6],\n",
    "                  'min_child_weight': [11],\n",
    "                  'silent': [1],\n",
    "                  'subsample': [0.7],\n",
    "                  'colsample_bytree': [0.7],\n",
    "                  'n_estimators': [100, 250, 500],\n",
    "                  'seed': [1337]}\n",
    "    \n",
    "    CV_xgb = GridSearchCV(estimator=xgb, \n",
    "                        param_grid=param_grid, \n",
    "                        cv= 8, \n",
    "                        verbose=True, n_jobs=-1, scoring = \"neg_mean_squared_error\", return_train_score=True)\n",
    "    CV_xgb.fit(X, y)\n",
    "    \n",
    "    return CV_xgb\n",
    "\n",
    "def dt_regression(X,y):\n",
    "    \n",
    "    dt = tree.DecisionTreeRegressor()\n",
    "\n",
    "    parameters = {\n",
    "              'min_samples_leaf':[5, 10, 15],\n",
    "              'ccp_alpha': [0.0, 0.2, 0.6]}\n",
    "\n",
    "    CV_dt = GridSearchCV(dt, parameters, n_jobs=-1, cv = 8,\n",
    "                       verbose=2, scoring = \"neg_mean_squared_error\", refit=True)\n",
    "    \n",
    "    CV_dt.fit(X, y)\n",
    "\n",
    "    return CV_dt\n",
    "\n",
    "def dt_classifier(X,y):\n",
    "    \n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "    parameters = {'criterion': [\"gini\"],\n",
    "              'min_samples_leaf':[5, 10, 15],\n",
    "              'ccp_alpha': [0.0, 0.2, 0.6]}\n",
    "\n",
    "    CV_dt = GridSearchCV(dt, parameters, n_jobs=-1,\n",
    "                       verbose=2, refit=True)\n",
    "    \n",
    "    CV_dt.fit(X, y)\n",
    "\n",
    "    return CV_dt\n",
    "\n",
    "def l1_regression(X, y):\n",
    "    model = LassoCV(cv=8, random_state=42, n_alphas=6, max_iter = 100000)\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "    \n",
    "def l1_classification(X, y):\n",
    "    kfold = StratifiedKFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    alphas = l1_min_c(X, y, loss='log') * np.logspace(0, 7, 3)\n",
    "    model = LogisticRegressionCV(Cs=alphas, cv=kfold, random_state=42, \n",
    "                                penalty='l1', solver='saga')\n",
    "    model.fit(X,y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For random forest; regression errors looks quite high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.729645030373415\n",
      "2.54051259002056\n",
      "2.4703788382753524\n"
     ]
    }
   ],
   "source": [
    "print(-cv_rf_r.best_score_)\n",
    "print(-cv_rf_r.score(X_test, y_test_reg))\n",
    "print(-cv_rf_r.score(X_train, y_train_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For decision tree; regression errors looks quite high. It is high even for the training set. This means, there was a problem in converging. Complexity parameter is not high and minimum samples per leaf is at minimum. Despite that training error is quite high. With this setting I would have expected the model to overfit. \n",
    "\n",
    "The problem gets more interesting when we check the predictions. All predictions are same; for the train and test data. All leaves have the same prediction, which shouldn't have happened in a normal setting. It looks like decision tree somehow underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 9 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8923748625675127\n",
      "{'ccp_alpha': 0.2, 'min_samples_leaf': 5}\n",
      "2.669620912840165\n",
      "2.8894195684955943\n"
     ]
    }
   ],
   "source": [
    "cv_dt_r = dt_regression(X_train, y_train_reg)\n",
    "\n",
    "print(-cv_dt_r.best_score_)\n",
    "print(cv_dt_r.best_params_)\n",
    "print(-cv_dt_r.score(X_test, y_test_reg))\n",
    "print(-cv_dt_r.score(X_train, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8137101, 2.8137101, 2.8137101, ..., 2.8137101, 2.8137101,\n",
       "       2.8137101])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dt_r.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers for random forest is better than the decision tree; all errors are lower. It looks like it started to train a bit but I would say it still looks underfit. All the predictions are higher than 2 (not a good distribution when we think of the data). Cross validation error is higher than test data; I wouldn't expect this to happen in a fit/overfit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.729645030373415\n",
      "{'bootstrap': True, 'max_depth': 4, 'max_features': 15, 'min_samples_leaf': 5, 'n_estimators': 500}\n",
      "2.54051259002056\n",
      "2.4703788382753524\n"
     ]
    }
   ],
   "source": [
    "cv_rf_r = rf_regression(X_train, y_train_reg)\n",
    "\n",
    "print(-cv_rf_r.best_score_)\n",
    "print(cv_rf_r.best_params_)\n",
    "print(-cv_rf_r.score(X_test, y_test_reg))\n",
    "print(-cv_rf_r.score(X_train, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6236167 , 3.04900216, 2.67673295, 3.33700594, 2.4871905 ,\n",
       "       2.627531  , 3.30118011, 3.46043992, 2.83870432, 3.43406951,\n",
       "       2.46830138, 2.92345242, 3.33012133, 2.33124417, 2.57195576,\n",
       "       2.81047456, 2.67285084, 2.71185489, 2.29038249, 2.39967807,\n",
       "       3.73719706, 2.69967846, 3.71110467, 3.18315196, 2.45733046,\n",
       "       3.43398062, 3.40782632, 2.90153663, 3.2853965 , 3.23498133,\n",
       "       2.64657973, 2.3518162 , 3.44869131, 2.55391889, 2.86056233,\n",
       "       3.24490946, 2.56759826, 2.66106908, 2.42327898, 2.79787657,\n",
       "       2.71007236, 2.69105358, 2.71520926, 2.16767988, 3.13653252,\n",
       "       2.72400601, 2.1162308 , 3.55102504, 2.73865866, 2.38814098,\n",
       "       3.03203635, 3.84053111, 3.50753503, 3.10583663, 3.30191883,\n",
       "       2.40058203, 2.39200124, 2.54515355, 3.15657082, 3.19410253,\n",
       "       3.36409671, 3.46812834, 3.50573284, 3.10554231, 2.60468967,\n",
       "       2.69965448, 2.56460014, 2.65831119, 2.89996896, 3.1385708 ,\n",
       "       2.72998316, 2.44525282, 3.35093077, 3.0177742 , 3.87377433,\n",
       "       2.65183463, 3.34656034, 2.38761121, 2.71459514, 2.56946035,\n",
       "       2.61831681, 2.34409877, 2.72324606, 3.20722201, 3.35473332,\n",
       "       3.45745701, 2.83809582, 2.48208725, 2.23459147, 2.29876319,\n",
       "       3.37731714, 2.31303527, 3.44104536, 2.67381384, 2.35757838,\n",
       "       3.26334599, 3.31215   , 2.63702932, 2.51162723, 3.74575338,\n",
       "       3.28556763, 2.7132282 , 3.21992788, 2.70891898, 2.5833911 ,\n",
       "       2.49669012, 2.23575418, 2.57954344, 3.29595935, 2.465408  ,\n",
       "       3.42411029, 2.1986477 , 2.66640242, 2.9608913 , 2.93859466,\n",
       "       2.42608802, 2.29732272, 2.60262056, 2.83948968, 2.30047725,\n",
       "       2.66946069, 2.56387507, 2.53356527, 3.37785327, 2.85336329,\n",
       "       3.38527496, 2.82896919, 2.32008428, 2.442233  , 3.2434494 ,\n",
       "       2.49844976, 3.21924298, 2.64990523, 3.59481373, 3.36775145,\n",
       "       2.72146848, 2.31885259, 3.03469789, 2.47565903, 3.00615782,\n",
       "       2.60174659, 2.74705619, 2.74222753, 3.30160401, 2.59718182,\n",
       "       2.63271731, 2.63655361, 2.69574431, 2.30914907, 2.68321883,\n",
       "       2.40269807, 2.9905404 , 2.27892595, 3.33529499, 2.42608749,\n",
       "       2.53167369, 2.62030853, 2.4285827 , 2.52123505, 4.0449909 ,\n",
       "       2.71750451, 3.46545308, 3.4930866 , 2.9762792 , 2.60804663,\n",
       "       2.40601458, 2.37078364, 3.76060572, 2.33154119, 2.69992535,\n",
       "       2.47846794, 3.26409087, 2.35450907, 3.31368498, 3.13034149,\n",
       "       2.46220715, 3.11184281, 2.6645664 , 2.62008159, 2.51255332,\n",
       "       3.94540792, 3.31978622, 3.04854444, 2.71131804, 2.40142238,\n",
       "       2.47770129, 2.46231623, 2.63340452, 3.47867203, 2.48704411,\n",
       "       2.77694914, 2.47380159, 3.34950611, 3.15626402, 3.35354707,\n",
       "       3.29200662, 3.17272414, 2.69392937, 2.65352477, 2.63857634,\n",
       "       2.84352217, 2.35818507, 3.20951165, 2.65870347, 2.54237151,\n",
       "       2.69227629, 3.50880835, 2.83492661, 2.65212991, 2.50597557,\n",
       "       3.21580615, 2.11487442, 3.39923482, 3.47612067, 2.39699127,\n",
       "       3.3686175 , 2.05097086, 2.24630208, 2.18900186, 2.89143951,\n",
       "       3.21238129, 2.54991619, 3.38097632, 2.46902783, 2.08695704,\n",
       "       2.70161777, 3.04346932, 2.69906722, 2.68577775, 2.12966648,\n",
       "       3.32146938, 2.41545903, 3.31161031, 3.45589913, 2.59214312,\n",
       "       2.39621667, 3.01465618, 2.51884393, 3.293099  , 2.37746238,\n",
       "       2.68835856, 3.22742396, 2.28475253, 2.39890062, 3.36614187,\n",
       "       2.90140019, 2.33551898, 2.48524574, 3.03955615, 2.31198284,\n",
       "       2.70312923, 2.44041937, 2.69555995, 2.43560533, 2.65528473,\n",
       "       2.94478221, 2.43363647, 2.48040534, 3.15899952, 2.68620517,\n",
       "       2.83081343, 3.23101118, 2.68833401, 2.70399662, 3.22301631,\n",
       "       2.73608658, 2.83889921, 2.61244285, 2.48029177, 2.54208082,\n",
       "       3.49677147, 2.89509512, 3.25564263, 2.44787772, 2.8357783 ,\n",
       "       3.35099158, 3.07594094, 3.11554154, 2.25530557, 3.28134773,\n",
       "       2.24039521, 3.2634026 , 3.02904845, 2.65502583, 3.01898293,\n",
       "       3.26068767, 2.57760847, 2.45705302, 2.69759292, 2.46686647,\n",
       "       2.58756507, 2.47372393, 3.24466016, 2.63798677, 3.75687013,\n",
       "       2.82790317, 2.42605895, 2.18303388, 2.10087825, 2.62029834,\n",
       "       3.48685539, 3.35422946, 2.72058345, 2.5156882 , 2.4955983 ,\n",
       "       2.57617176, 4.03690364, 3.37229141, 2.4351881 , 3.46967295,\n",
       "       2.23290261, 2.820091  , 3.35055041, 2.4188118 , 3.24927141,\n",
       "       2.45544573, 3.38044528, 2.38043153, 3.44179262, 2.62377206,\n",
       "       2.7749158 , 2.4217817 , 2.66649699, 3.29518426, 3.0379606 ,\n",
       "       3.34932868, 2.480963  , 2.41375982, 2.38652866, 3.23621522,\n",
       "       3.33761866, 2.76174419, 2.49055126, 2.41549873, 2.25996723,\n",
       "       2.53857299, 2.69505667, 3.2609289 , 2.50059303, 2.48108905,\n",
       "       2.45576098, 2.1625781 , 2.14421654, 3.33549713, 3.18427675,\n",
       "       2.712496  , 2.46618972, 3.42947831, 3.23952521, 2.43759102,\n",
       "       2.66227045, 3.44942437, 3.14861531, 3.23372797, 2.65515096,\n",
       "       3.91323987, 3.38611014, 2.70203501, 2.34047035, 3.21484559,\n",
       "       2.28780468, 3.65748223, 3.12691527, 3.30891883, 2.31250351,\n",
       "       3.13485047, 2.31993274, 3.24937594, 3.42621439, 3.36680385,\n",
       "       2.30701821, 2.68806924, 2.20277702, 3.25335456, 2.16187378,\n",
       "       2.63354776, 2.73319318, 3.34462088, 3.3623585 , 2.4687469 ,\n",
       "       2.64805428, 2.70779546, 2.63330782, 3.21861366, 2.68917028,\n",
       "       2.38197033, 3.05172312, 3.13768395, 3.36991431, 3.38576916,\n",
       "       3.86910568, 2.64666111, 2.50247672, 3.22938624, 2.68049567,\n",
       "       3.4970002 , 2.48218553, 2.09240704, 3.45736895, 2.78421341,\n",
       "       3.33636376, 2.47460699, 3.40998819, 3.31022763, 2.90415387,\n",
       "       2.41547489, 2.6534024 , 2.45962944, 3.33294021, 3.00720204,\n",
       "       2.7799938 , 2.35256823, 3.43375806, 3.38196961, 2.46228836,\n",
       "       2.27752184, 3.56982144, 2.49503454, 2.31816589, 2.68783375,\n",
       "       2.49124676, 2.59487798, 2.31342066, 2.68986777, 3.37255268,\n",
       "       2.23029151, 2.44296491, 3.04506177, 2.6964483 , 2.78049769,\n",
       "       2.68764174, 3.15943908, 2.84951502, 2.52767636, 2.76354707,\n",
       "       3.38096788, 2.70493096, 3.18792689, 3.2904609 , 2.68174322,\n",
       "       2.42129306, 2.16517013, 2.58498245, 3.27582185, 2.63971773,\n",
       "       3.39176886, 2.35113244, 3.1293876 , 2.56429846, 3.16296983,\n",
       "       3.22313758, 3.90528326, 3.4272895 , 2.54784258, 2.14129922,\n",
       "       3.39533438, 2.46024651, 2.7222956 , 2.63235925, 3.325878  ,\n",
       "       2.3993398 , 3.34431673, 2.33941349, 2.30214527, 3.02246886,\n",
       "       2.44105537, 3.32903174, 3.20147448, 2.65430681, 3.31107413,\n",
       "       3.4671383 , 2.58746021, 2.32920121, 2.29805603, 2.45743416,\n",
       "       2.58783185, 3.42288115, 2.67001856])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rf_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 27 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 21.9min finished\n",
      "C:\\Users\\erdem.banak\\AppData\\Local\\Continuum\\anaconda3\\envs\\erdem\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\erdem.banak\\AppData\\Local\\Continuum\\anaconda3\\envs\\erdem\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.746662934231389\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 2, 'min_child_weight': 11, 'n_estimators': 100, 'objective': 'reg:linear', 'seed': 1337, 'silent': 1, 'subsample': 0.7}\n",
      "2.5553155590548404\n",
      "2.388268514839198\n"
     ]
    }
   ],
   "source": [
    "cv_xgb_r = xgb_regression(X_train, y_train_reg)\n",
    "\n",
    "print(-cv_xgb_r.best_score_)\n",
    "print(cv_xgb_r.best_params_)\n",
    "print(-cv_xgb_r.score(X_test, y_test_reg))\n",
    "print(-cv_xgb_r.score(X_train, y_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5863595, 2.671107 , 2.5874593, 3.6336474, 2.4392443, 2.7245402,\n",
       "       3.315366 , 3.587971 , 2.7535985, 3.375648 , 2.5849364, 2.906398 ,\n",
       "       3.233523 , 2.4271345, 2.6097345, 2.637575 , 2.4807553, 2.4867806,\n",
       "       2.2416892, 2.3799667, 3.7591326, 2.6010094, 3.906064 , 3.1835735,\n",
       "       2.5005357, 3.3862474, 3.6289053, 2.3334913, 3.1674533, 3.1394184,\n",
       "       2.6507397, 2.335025 , 3.3594854, 2.5839431, 2.9311967, 3.304246 ,\n",
       "       2.436667 , 2.692973 , 2.4495168, 2.751389 , 2.803674 , 2.698357 ,\n",
       "       2.5300484, 2.1825762, 3.3365173, 2.7302969, 2.030344 , 3.7680144,\n",
       "       2.8403285, 2.5413132, 2.6826813, 3.6968384, 3.5168536, 2.5392113,\n",
       "       3.182745 , 2.3487134, 2.493506 , 2.4050527, 2.945298 , 3.218545 ,\n",
       "       3.2859282, 3.383977 , 3.597432 , 3.06544  , 2.5727732, 2.703249 ,\n",
       "       2.563501 , 2.5305543, 3.0632694, 3.129874 , 2.8473687, 2.4729965,\n",
       "       3.1969526, 2.8859558, 4.063395 , 2.7507865, 3.310447 , 2.3463278,\n",
       "       2.7070758, 2.589302 , 2.8326712, 2.3953757, 2.7462268, 2.949476 ,\n",
       "       3.2482271, 3.0781186, 2.9137988, 2.6461353, 2.191309 , 2.3295937,\n",
       "       3.5740087, 2.1487393, 3.2227745, 2.587634 , 2.300798 , 3.209725 ,\n",
       "       3.2367249, 2.5758936, 2.521786 , 4.039811 , 3.1839876, 2.6356618,\n",
       "       3.3951688, 2.7283664, 2.5718277, 2.6677907, 2.424539 , 2.5887234,\n",
       "       3.0906835, 2.465934 , 3.5666826, 2.27382  , 2.6116376, 2.9595997,\n",
       "       3.010795 , 2.4062338, 2.1313195, 2.638417 , 2.7894084, 2.2099972,\n",
       "       2.5894368, 2.528444 , 2.5289032, 3.3947186, 2.6420023, 3.258313 ,\n",
       "       2.7040834, 2.4591439, 2.4284453, 3.1429446, 2.6719754, 3.0968525,\n",
       "       2.474742 , 3.5476437, 3.3182683, 2.7245135, 2.29392  , 2.9337373,\n",
       "       2.500023 , 2.9243069, 2.4702086, 2.4820538, 2.7577593, 3.1308193,\n",
       "       2.5564969, 2.6701965, 2.4938893, 2.6777685, 2.2728014, 2.7351065,\n",
       "       2.5895154, 2.650843 , 2.1755958, 3.0955667, 2.3981023, 2.8080487,\n",
       "       2.5750482, 2.4963222, 2.5043728, 4.2448325, 2.8456233, 3.2396474,\n",
       "       3.7384348, 2.7742424, 2.592025 , 2.3554802, 2.4871287, 3.6867144,\n",
       "       2.295981 , 2.6549642, 2.496026 , 3.2303126, 2.1656148, 3.1052144,\n",
       "       3.271421 , 2.5558329, 3.1529005, 2.6235042, 2.6665847, 2.491653 ,\n",
       "       3.7425835, 3.188985 , 3.08115  , 2.7896717, 2.2420268, 2.4921746,\n",
       "       2.3567648, 2.5366442, 3.354694 , 2.5938296, 2.6608362, 2.5496018,\n",
       "       3.3320234, 3.1810706, 3.3144603, 3.4067075, 2.9895341, 2.8058434,\n",
       "       2.5453763, 2.5407999, 2.7556942, 2.361949 , 3.2415943, 2.5722337,\n",
       "       2.6732976, 2.8005376, 3.4156272, 2.822812 , 2.728288 , 2.468553 ,\n",
       "       3.0264251, 2.0262218, 3.2254944, 3.449462 , 2.4447865, 3.276003 ,\n",
       "       2.1475267, 2.3107784, 2.0885592, 2.6727166, 3.1047485, 2.7136378,\n",
       "       3.3782184, 1.904256 , 2.2246697, 2.9335408, 3.0985367, 2.7682736,\n",
       "       2.6953728, 2.122324 , 3.431683 , 2.2197237, 3.1804342, 3.7314432,\n",
       "       2.7164721, 2.4686375, 3.0836701, 2.6249218, 2.998178 , 2.4561415,\n",
       "       2.684319 , 3.2372744, 2.2672672, 2.618671 , 3.4758623, 2.8881814,\n",
       "       2.5310304, 2.559958 , 3.0418828, 2.265867 , 2.8200169, 2.369475 ,\n",
       "       2.763746 , 2.3377972, 2.6534941, 2.8518257, 2.399239 , 2.7301948,\n",
       "       3.1792104, 2.809005 , 2.8904722, 3.3449404, 2.665296 , 2.831185 ,\n",
       "       3.0995617, 2.7505157, 2.5470583, 2.5611994, 2.4177096, 2.374292 ,\n",
       "       3.5701013, 2.5041957, 3.0587444, 2.3996897, 2.6073005, 3.339107 ,\n",
       "       2.886999 , 3.365906 , 2.4569688, 3.2445707, 2.2986736, 3.2297468,\n",
       "       2.9028914, 2.581095 , 3.0809836, 3.1811967, 2.4664226, 2.2398677,\n",
       "       2.830588 , 2.4094267, 2.6560445, 2.4344933, 3.3017976, 2.8347402,\n",
       "       4.0870647, 2.8628376, 2.462789 , 2.1600795, 2.130602 , 2.7266984,\n",
       "       3.7126708, 3.409943 , 2.663221 , 2.5796087, 2.465864 , 2.5290053,\n",
       "       3.7317529, 3.2883384, 2.4075441, 3.3853717, 2.2962573, 2.7249856,\n",
       "       3.2308383, 2.3934124, 3.1343203, 2.3595955, 3.381512 , 2.2765908,\n",
       "       3.5563955, 2.5621107, 2.6516862, 2.5204859, 2.613702 , 3.3788319,\n",
       "       2.868445 , 3.2526133, 2.4159012, 2.3618307, 2.3068504, 3.1605613,\n",
       "       3.1523266, 2.8214824, 2.4463954, 2.501801 , 2.3140504, 2.5851073,\n",
       "       2.719183 , 3.3838532, 2.4932156, 2.3861928, 2.5711935, 2.2857997,\n",
       "       2.239669 , 3.330831 , 3.20674  , 2.8136313, 2.5690587, 3.4074972,\n",
       "       3.0684116, 2.4697933, 2.3625169, 3.59751  , 3.0868747, 3.4201634,\n",
       "       2.7204616, 4.1177893, 3.418923 , 2.8670926, 2.4126964, 2.9595892,\n",
       "       2.3823223, 3.6886756, 3.1640034, 3.3425584, 2.266696 , 3.065355 ,\n",
       "       2.224862 , 3.187096 , 3.3189416, 3.2311144, 2.4803662, 2.6281674,\n",
       "       2.2268708, 3.2763941, 2.330628 , 2.5989225, 2.7153218, 3.276231 ,\n",
       "       3.4655323, 2.5475304, 2.6275008, 2.6195805, 2.5688205, 3.2431815,\n",
       "       2.5910614, 2.4437482, 3.0681615, 3.1725786, 3.264208 , 3.502445 ,\n",
       "       3.929354 , 2.7058568, 2.6580062, 3.2789383, 2.6022472, 3.5823145,\n",
       "       2.4069083, 2.2008796, 3.3540056, 2.7481577, 3.2464268, 2.5659108,\n",
       "       3.3957806, 2.9312136, 2.9442477, 2.5404222, 2.6835408, 2.5245593,\n",
       "       3.339972 , 2.9729595, 2.8157823, 2.3969579, 3.4877553, 3.4168568,\n",
       "       2.3937225, 2.353082 , 3.8380759, 2.4785237, 2.2803428, 2.7618861,\n",
       "       2.5226061, 2.651452 , 2.1144004, 2.7243626, 3.2431042, 2.1445885,\n",
       "       2.5186305, 2.7734387, 2.714228 , 2.875621 , 2.7226982, 3.059813 ,\n",
       "       2.807404 , 2.5052428, 2.91369  , 2.4549108, 2.8461342, 3.3406737,\n",
       "       3.311743 , 2.808157 , 2.4663925, 2.1978421, 2.6150596, 3.2501607,\n",
       "       2.614097 , 3.4387112, 2.342813 , 3.2310407, 2.753452 , 3.225612 ,\n",
       "       3.0482402, 3.8153517, 3.3712683, 2.4109445, 2.050261 , 3.3512943,\n",
       "       2.5447514, 2.7124763, 2.45756  , 3.3866239, 2.366868 , 3.5068922,\n",
       "       2.417043 , 2.416082 , 2.6291866, 2.339768 , 3.5281553, 3.1521192,\n",
       "       2.6055408, 3.4125786, 3.6611974, 2.8409758, 2.390367 , 2.4738336,\n",
       "       2.4536257, 2.4584289, 3.5581458, 2.3966868], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022025570613825485"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv_ls = l1_regression(X_train, y_train_reg)\n",
    "\n",
    "cv_ls.score(X_test, y_test_reg)\n",
    "cv_ls.score(X_train, y_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cv_ls.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
